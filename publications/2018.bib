@article{Dai2018,
pdf = {2018-Dai Yunpeng-TBME.pdf},
abstract = {Objective: In vivo bioluminescence imaging (BLI) is a promising tool for monitoring the growth and metastasis of tumors. However, quantitative BLI research based on intravenous (IV) injection is limited, which greatly restricts its further application. To address this problem, we designed a pharmacokinetic (PK) model which is suitable for applying on IV administration of small amounts of D-Luciferin. Methods : After three weeks of post-implantation, mkn28-luc xenografted mice were subjected to 40 min dynamic BLI immediately following D-Luciferin intravenous injection on days 1, 3, 5, 7 and 9. Further, the PK model was applied on dynamic BLI data to obtain the sum of kinetic rate constants (SKRC). Results : Results showed that the SKRC values decreased rapidly with the growth of the tumor. There was a statistical difference between the SKRC values measured at different time points, while the time point of luminous intensity peak (TLP) was unaffected by the growth of the tumor. Conclusions : In short, our results imply that dynamic BLI combined with our PK model can predict tumor growth earlier and with higher sensitivity compared to the conventional method, which is crucial for improving drug evaluation efficacy. In addition, the dynamic BLI may provide a valuable reference for the noninvasive acquiring arterial input function (AIF), which may also provide a new application prospect for hybrid PET-optical imaging.},
author = {Dai, Yunpeng and Wang, Guodong and Chen, Duofang and Yin, Jipeng and Zhan, Yonghua and Nie, Yongzhan and Liang, Jimin and Chen, Xueli},
file = {:E$\backslash$:/Mendeley Papers/2018/IEEE Transactions on Biomedical Engineering/2018 - IEEE Transactions on Biomedical Engineering - Intravenous administration-oriented pharmacokinetic model for dynamic bioluminescen.pdf:pdf},
journal = {IEEE Transactions on Biomedical Engineering},
title = {{Intravenous administration-oriented pharmacokinetic model for dynamic bioluminescence imaging}},
year = {2018}
}

@article{Niu2018,
pdf = {2018-Niu Chuang-TGRS-Online.pdf},
abstract = {In this paper, we propose a novel weakly supervised semantic segmentation (WSSS) method that uses image tags as supervision to achieve joint pixel-level localization of the key local structure (KLS) and image-level classification of the aurora images captured by the ground-based optical all-sky imager. First, a patch-scale model (PSM) based on the small-scale structure of aurora is designed to identify the type-specific regions for each training image. Second, a region-scale model is trained with the identified type-specific regions to coarsely localize the KLS from multiple sizes of field of view, based on which the aurora image is classified. Finally, given the predicted image type, the PSM further refines the KLS in a pixel level. By localizing KLS from coarse to fine, the proposed method captures both overall shape with a bottom-up processing and local structure details of aurora in a top-down manner. Extensive experiments on the expert labeled data sets have demonstrated the efficacy of the proposed method in benchmarking with the state-of-the-art WSSS methods.},
author = {Niu, Chuang and Zhang, Jun and Wang, Qian and Liang, Jimin},
doi = {10.1109/TGRS.2018.2848725},
file = {:E$\backslash$:/Mendeley Papers/2018/IEEE Transactions on Geoscience and Remote Sensing/2018 - IEEE Transactions on Geoscience and Remote Sensing - Weakly Supervised Semantic Segmentation for Joint Key Local Structure Locali.pdf:pdf},
issn = {01962892},
journal = {IEEE Transactions on Geoscience and Remote Sensing},
keywords = {Analytical models,Aurora image analysis,Image segmentation,Ion radiation effects,Magnetosphere,Semantics,Shape,Training,bag of visual words (BoVW),convolutional neural networks (CNNs),weakly supervised semantic segmentation (WSSS).},
pages = {1--14},
publisher = {IEEE},
title = {{Weakly Supervised Semantic Segmentation for Joint Key Local Structure Localization and Classification of Aurora Image}},
year = {2018}
}
@article{Zhan2018,
pdf = {2018-Zhan Yonghua-JBN.pdf},
abstract = {Manganese-based nanoparticles (NPs) have recently attracted much attention in the field of biomedical imaging due to their impressive enhanced T-1 contrast ability. Although the reported manganese-based NPs have exhibited good imaging capabilities as contrast agents, it is still urgent to develop novel multifunctional manganese-based imaging probes for future biomedical imaging, especially PET/MRI probes. Herein, we present chelator-free zirconium-89 (Zr-89, t(1/2): 78.4 h) labeling of manganese oxide NPs (Mn3O4@PEG) with similar to 78% labeling yield and good stability. Serial positron emission tomography (PET) and magnetic resonance imaging (MRI) studies non-invasively assessed the biodistribution patterns of the NPs and the feasibility of in vivo dual-modality imaging and lymph-node mapping. Since Mn3O4 NPs exhibited desirable properties for enhanced T-1 imaging and the simplicity of chelator-free radiolabeling, [Zr-89]Mn3O4@PEG NPs offer a novel, simple, safe and accurate nanoplatforms for future precise cancer imaging and diagnosis.},
author = {Zhan, Yonghua and Ehlerding, Emily B. and Shi, Sixiang and Graves, Stephen A. and Goel, Shreya and Engle, Jonathan W. and Liang, Jimin and Cai, Weibo},
doi = {10.1166/jbn.2018.2498},
file = {:E$\backslash$:/Mendeley Papers/2018/Journal of Biomedical Nanotechnology/2018 - Journal of Biomedical Nanotechnology - Intrinsically Zirconium-89-Labeled Manganese Oxide Nanoparticles for In Vivo Dual-Modality.pdf:pdf},
issn = {1550-7033},
journal = {Journal of Biomedical Nanotechnology},
keywords = {magnetic resonance imaging,manganese oxide nanoparticles,positron emission tomography,zirconium-89},
number = {5},
pages = {900--909},
title = {{Intrinsically Zirconium-89-Labeled Manganese Oxide Nanoparticles for In Vivo Dual-Modality Positron Emission Tomography and Magnetic Resonance Imaging}},
url = {http://www.ingentaconnect.com/content/10.1166/jbn.2018.2498},
volume = {14},
year = {2018}
}
@article{Li2018,
pdf = {2018-Zhan Yonghua-Nanomedicine.pdf},
abstract = {Cancer metastasis is one of the biggest challenges in cancer treatments since it increases the likelihood that a patient will die from the disease. Therefore, the availability of techniques for the early detection and quantification of tumors is very important. We have prepared cyanine 7.5 NHS ester (Cy7.5) and folic acid (FA) conjugated biodegradable mesoporous silica nanoparticles (bMSN@Cy7.5-FA NPs) (~100 nm) for visualizing tumors in vivo. The fluorescence spectra revealed that the emission peak of bMSN@Cy7.5-FA NPs had a red-shift of 1 nm. Confocal immunofluorescent images showed that bMSN@Cy7.5-FA NPs had an excellent targeting ability for visualizing cancer cells. In vivo fluorescence imaging has been conducted using an orthotopic model for pancreatic cancer within 48 h, and the fluorescence intensity reached a maximum at a post injection time-point of 12 h, which demonstrated that the use of bMSN@Cy7.5-FA NPs provides an excellent imaging platform for tumor precision therapy in mice.},
author = {Li, Hanrui and Li, Ke and Dai, Yunpeng and Xu, Xinyi and Cao, Xu and Zeng, Qi and He, Huyulong and Pang, Liaojun and Liang, Jimin and Chen, Xueli and Zhan, Yonghua},
doi = {10.1016/j.nano.2018.04.018},
file = {:E$\backslash$:/Mendeley Papers/2018/Nanomedicine Nanotechnology, Biology, and Medicine/2018 - Nanomedicine Nanotechnology, Biology, and Medicine - In vivo near infrared fluorescence imaging and dynamic quantification of pan.pdf:pdf},
issn = {15499642},
journal = {Nanomedicine: Nanotechnology, Biology, and Medicine},
keywords = {Fluorescence imaging,Folic acid,Mesoporous silica nanoparticles,Pancreatic cancer,Quantification,Tumor metastasis},
number = {6},
pages = {1867--1877},
publisher = {Elsevier Inc.},
title = {{In vivo near infrared fluorescence imaging and dynamic quantification of pancreatic metastatic tumors using folic acid conjugated biodegradable mesoporous silica nanoparticles}},
url = {https://doi.org/10.1016/j.nano.2018.04.018},
volume = {14},
year = {2018}
}
@article{Zhao2018,
pdf = {2018-Zhao Fengjun-MBEC.pdf},
author = {Zhao, Fengjun and Sun, Feifei and Hou, Yuqing and Chen, Yanrong and Chen, Dongmei and Cao, Xin and Yi, Huangjian and Wang, Bin and He, Xiaowei and Liang, Jimin},
doi = {10.1007/s11517-017-1717-8},
file = {:E$\backslash$:/Mendeley Papers/2018/Medical {\&} Biological Engineering {\&} Computing/2018 - Medical {\&} Biological Engineering {\&} Computing - A monocentric centerline extraction method for ring-like blood vessels.pdf:pdf},
issn = {0140-0118},
journal = {Medical {\&} Biological Engineering {\&} Computing},
keywords = {Centerline extraction,Blood vessels,Information fusion,Monocentric processing,blood vessels,centerline extraction,information fusion,monocentric processing},
number = {4},
pages = {695--707},
publisher = {Medical {\&} Biological Engineering {\&} Computing},
title = {{A monocentric centerline extraction method for ring-like blood vessels}},
url = {http://link.springer.com/10.1007/s11517-017-1717-8},
volume = {56},
year = {2018}
}
@inproceedings{Chen2018,
pdf = {2018-SPIE MI-Chen Fei.pdf},
abstract = {Coronary artery disease (CAD) is one of the leading causes of death worldwide. The computed tomography angiography (CTA) is increasingly used to diagnose CAD due to its non-invasive nature and high-resolution three-dimensional (3D) imaging capability of the coronary artery anatomy. CTA allows for identification and grading of stenosis by evaluating the degree of narrowing of the blood-filled coronary artery lumen. Both identification and grading rely on the precise segmentation of the coronary arteries on CTA images. In this paper, a fully automatic segmentation framework is proposed to extract the coronary arteries from the whole cardiac CTA images. The framework adopts a paired multi-scale 3D deep convolutional neural networks (CNNs) to identify which voxels belong to the vessel lumen. Voxels that may belong to coronary artery lumen are recognized by the first CNN in the pair and both artery positives and artery-like negatives are distinguished by the second one. Each CNN is assigned to a different task. They share the same architecture in common but with different weights. In order to combine local and larger contextual information, we adopt a dual pathway architecture that can process the input image simultaneously on multiple scales. The experiments were performed on a CTA dataset from 44 patients. 35 CTA scans are used for training and the rests for testing. The proposed segmentation framework achieved a mean Dice similarity coefficient (DSC) of 0.8649 and mean surface distance (MSD) of 0.5571 with reference to manual annotations. Experimental results show that the proposed framework is capable of performing complete, accurate and robust segmentation of the coronary arteries.},
author = {Chen, Fei and Li, Yu and Tian, Tian and Cao, Feng and Liang, Jimin},
booktitle = {Medical Imaging 2018: Biomedical Applications in Molecular, Structural, and Functional Imaging},
doi = {10.1117/12.2293289},
file = {:E$\backslash$:/Mendeley Papers/2018/Medical Imaging 2018 Biomedical Applications in Molecular, Structural, and Functional Imaging/2018 - Medical Imaging 2018 Biomedical Applications in Molecular, Structural, and Functional Imaging - Automatic coronary artery lum.pdf:pdf},
isbn = {9781510616455},
issn = {16057422},
keywords = {3D convolutional neural network,Cardiac computed tomography angiography,Coronary arteries segmentation,Deep learning},
number = {March},
pages = {99},
title = {{Automatic coronary artery lumen segmentation in computed tomography angiography using paired multi-scale 3D CNN}},
url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10578/2293289/Automatic-coronary-artery-lumen-segmentation-in-computed-tomography-angiography-using/10.1117/12.2293289.full},
volume = {10578},
year = {2018}
}
